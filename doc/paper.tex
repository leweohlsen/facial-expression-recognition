%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Facial Expresion Recognition with Convolutional Neural Networks
% 
% Lewe Ohlsen
% Fachhochschule Wedel
%
% Latex Template by Frits Wenneker (http://www.howtotex.com)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[twoside]{article}

\usepackage{lipsum} % Package to generate dummy text throughout this template
\usepackage{graphicx} % Figures from matplotlib
\graphicspath{ {figures/} }

\usepackage[sc]{mathpazo} % Use the Palatino font
\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\linespread{1.05} % Line spacing - Palatino needs more space between lines
\usepackage{microtype} % Slightly tweak font spacing for aesthetics

\usepackage[hmarginratio=1:1,top=32mm,columnsep=20pt]{geometry} % Document margins
\usepackage{multicol} % Used for the two-column layout of the document
\usepackage[hang, small,labelfont=bf,up,textfont=it,up]{caption} % Custom captions under/above floats in tables or figures

\usepackage{booktabs} % Horizontal rules in tables
\usepackage{float} % Required for tables and figures in the multi-column environment - they need to be placed in specific locations with the [H] (e.g. \begin{table}[H])
\usepackage{hyperref} % For hyperlinks in the PDF
\usepackage{cite} % BibTex

\usepackage{paralist} % Used for the compactitem environment which makes bullet points with less space between them

\usepackage{abstract} % Allows abstract customization
\renewcommand{\abstractnamefont}{\normalfont\bfseries} % Set the "Abstract" text to bold
\renewcommand{\abstracttextfont}{\normalfont\small\itshape} % Set the abstract itself to small italic text

\usepackage{titlesec} % Allows customization of titles
\usepackage[utf8]{inputenc}
%\renewcommand\thesection{\Roman{section}} % Roman numerals for the sections
%\renewcommand\thesubsection{\Roman{subsection}} % Roman numerals for subsections
\titleformat{\section}[block]{\large\scshape\centering\bfseries}{\thesection.}{1em}{} % Change the look of the section titles
\titleformat{\subsection}[block]{}{\thesubsection.}{1em}{} % Change the look of the section titles


%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\title{\vspace{-15mm}\fontsize{16pt}{10pt}\selectfont\textbf{Facial Expression Recognition with\\ Convolutional Neural Networks}} % Article title 

\author{
	\large
	\textsc{Lewe Ohlsen}\\[2mm] % Your name
	\normalsize Fachhochschule Wedel \\ % Your institution
	\normalsize \href{mailto:minf101062@fh-wedel.de}{minf101062@fh-wedel.de} % Your email address
	\vspace{-5mm}
}
\date{}

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Insert title

%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

\begin{abstract}

\noindent El barómetro es un instrumento de medición atmosérica, específicamente utilizado en la determinación de la fuerza por unidad de superficie ejercida por el peso de la atmósfera. Existe un gran número de equipos atmoféricos con distintos tipos de estos aparátos y son diariamente utilizados ya que la presión atmosférica juega un papel importante en la determinación y pronóstico del tiempo así como en el área de investigación al momento de realizarse experimentos ya que pueden llegar a afectar o hacer variar el funcionamiento de muchos aparatos electrónicos y mecánicos.

\end{abstract}

%----------------------------------------------------------------------------------------
%	ARTICLE CONTENTS
%----------------------------------------------------------------------------------------

\begin{multicols}{2} % Two-column layout throughout the main article text

\section{Introduction}

Automatically recognizing facial expressions is an interesting and challenging problem in many fields, including human computer interaction and artificial emotional intelligence. Facial expressions can be interpreted and categorized into six classes of basic emotion that seem to be found across all human cultures: anger, disgust, fear, happiness, sadness, and surprise \cite{ekman93}. This projects goal is to develop a classifier for real-time detection of these facial expressions.

%------------------------------------------------

\section{Related work}
In the last years, great progress was made on the problem of automatically detecting facial expression from images. Some researchers have attempted to derive emotions from detecting individual muscle movements in images of faces by identifying muscles and their degree of activation \cite{lien98}. Manual feature extraction tends to require expert knowledge and extra work for implementing complex algorithms, so it is convenient to implicitly extract relevant features from the data. This can be accomplished with Convolutional Neural Networks (CNNs) that are trained on a set of labeled images.

%------------------------------------------------

\section{Datasets}
To train an automatic classifier using deep learning technology, a dataset that describes the problem is required. Each image in the dataset is mapped to a matching integer class label for the corresponding emotion. Two datasets, FER2013 \cite{goodfel13} and CK+ \cite{cohn00} have been considered for training the deep learning model.

\subsection{FER-2013}
The FER-2013 dataset consists of roughly 37.000 images showing faces of people expressing a certain emotion. Most of the 48x48 pixel grayscale images are stock footage. These images have been centered on the persons faces to show a similar region in every sample. As this has been done automatically, some images are not centered correctly. Faces are depicted from very different angles, hence generalization of these samples is difficult. 

\begin{figure}[H]
	\includegraphics[width=0.48\textwidth]{class_dist}
	\caption{FER-2013 emotion class distribution}
\end{figure}

The class labels were crowd-sourced with Amazon Mechanical Turk, where quality work is not incentivized, so we can expect noisy labels to be a problem. It is expected that every subject shows only a single emotion, where in reality faces can express mixed emotions (e.g happiness and surprise). A research group at Microsoft decided to minimize label-noise in FER-2013 by re-labeling the dataset \cite{barsoum16}. Ten workers on Mechanical Turk were asked to label each image, yielding a probability distribution of emotion classes instead of a single class for each image.


\subsection{Cohn-Kanade (CK+)}
To augment the wild variety of FER-2013 images, a second, more conservative dataset with only frontal faces is considered. The Cohn-Kanade (CK+) dataset consists of 593 image sequences across 123 subjects. Each image sequence goes from a neutral facial expression to a "peak expression" according to the six basic emotions. Only 327 of the 593 image sequences are labeled with emotion data. This is because not all images fit the prototypic definition of the Facial Action Coding System (FACS) according to Ekman et al. CK+ also contains FACS data, in which facial action units (e.g raised eyebrow) are identified along with their degree of activation. To show that extracted features are not strictly required for training an automatic classifier, the FACS data is not used as input.

Figure of CK+ distribution with neutral images.

%------------------------------------------------

\section{Convolutional Neural Networks (CNNs)}
Convolutional Neural Networks are are a special kind of multi-layer artificial neural networks. CNNs have been around since the 1990s, however they have lead to breakthrough results in practical small-scale application with computational power becoming more affordable in the last years. Convolutional Neural Networks can recognize visual patterns directly from pixel images with very little preprocessing. 

Like a regular Artificial Neural Network, a CNN can be thought of as a function $f(x) = y$ where the input $x$ is an image of a face and $y$ is a probability distribution of the classes this image is predicted to belong to (e.g happiness, surprise, sadness). Input images are flattened in dimension from 48x48 pixels to a single 2304-dimensional vector. For training and predictions, multiple images can be fed into the network function at once. When feeding $n$ images to the computational graph, the shape of the input tensor (matrix) is [2304, $n$]. The associated output tensor is shaped [$n$, 7], where the second dimension is the probability for each of the seven emotion classes.

To effectively reduce dimensions between the input and output space and find a valid representation of the input image, a CNN is implemented using the TensorFlow API. In the layers of the computational graph, a sequence of operations is applied to the input image. 

\subsection{CNN Components}

\subsubsection{Convolutional Layer}
The convolutional layer is the core building block of a CNN. Each layer is initialized with a set of $n$ random two-dimensional filter matrices (eg 3x3 pixels) and a pixel-stride. When an image is put into the convolutional layer, each of the filters is moved across the height and width of the image, calculating a dot product between the filter matrix and the current section of the image. The resulting matrices of dot products are called feature maps. To introduce non-linearity to the operation, a ReLu activation function $f(n) = max(0, n)$ is used on the feature-maps element-wise. The filters in the convolutional layers are trained using a backpropagation algorithm. Intuitively, filters activate when they see different types of visual features, such as vertical or diagonal edges on the lower layers or, in the top convolutional layers, more complex patterns like eyebrows or mouths.

\subsubsection{Pooling Layer}
To progressively reduce dimensionality and computational cost, pooling layers can be found in the computational graph. Similar to the convolutional layer, filters are moved across the layer input, executing a pooling operation on each position. A common pooling operation is taking the max value on every filter position (Max-Pooling). For instance when pooling with a filter size of 3x3 pixels and a stride of 2 is applied to a 48x48 pixels image, the pooling output is a 24x24 pixels image.

\subsubsection{Fully-Connected layers}
In CNNs, fully connected layers are added at the top of the network. The advanced features that have been extracted in the top convolutional layers are usually connected to two or more layers of weighted nodes. On the first fully-connected layer, linear combinations of the feature maps activations are created. On top of that, linear transformations are applied to reduce the dimension to match the number of classes. A softmax function can be applied on the output layer to normalize the topmost fully connected layer into a valid probability distribution.


%------------------------------------------------

\section{Model Architecture and Training}
A deep CNN is implemented as a prediction model for classifying images of faces. The model architecture has been improved incrementally throughout the designing process. Hyperparameter Optimization has not been done programmatically but rather in a trial-and-error kind of way.

%\subsection{AlexNet-like CNN}
%For the Imagenet Challenge (REF) Alex … proposed a deep neural network (DNN) model consisting of alternating convolution and pooling layers with local response normalization in between, followed by three fully connected layers.

\subsection{Training Procedure}


%------------------------------------------------

\section{Discussion and Conclusion}

% - CNN robustness to occlusion, distortions and geometric transformations.
The final model scored an accuracy of ~75\% on a test-set of 3557 samples. In live predictions with a webcam, the classifier has shown to be a cool gadget to play around with. However, some emotions such as disgust and fear are hard to reproduce predictions for. This is most likely because the seven classes of emotion in the dataset are highly imbalanced. For instance disgust only has 500 samples while happy has much more. This results in biased predictions with higher probabilities of the majority classes. In order to balance the training dataset, data augmentation could be used: To increase the number of training examples for a given class, the images could be flipped horizontally or rotated in multiple random angles. For normalizing the images, it is a common practice to subtract the mean pixel intensities over the whole dataset from each picture. Given more time for this project, I would like to have experimented with such techniques of data augmentation. 



%----------------------------------------------------------------------------------------
%	REFERENCE LIST
%----------------------------------------------------------------------------------------

%\begin{thebibliography}{9}
%
%	% OpenCV Haarcascade Classifier
%	\bibitem{violajones}
%  	P. A. Viola and M. J. Jones. Robust real-time face detection.
%	International Journal of Computer Vision
%	57(2):137–154, 2004.
%
%	% the ICML 2013 workshop’s facial expression recognition challenge
%	\bibitem{replearning}
%	I. J. Goodfellow et al.
%	Challenges in representation learning: A report on three machine
%	learning contests.
%	Neural Networks
%	, 64:59 – 63, 2015.
%	Special Issue on ‘Deep Learning of Representations’
%	
%	%[LeCun and Bengio, 1995a]
%    %Y. LeCun and Y. Bengio. Convolutional networks for images, speech, and time-series. 
%    %In M. A. Arbib, 		editor, The Handbook of Brain Theory and Neural Networks. MIT Press, 1995
%    
%    % Paul Ekmans 1969 research paper "Facial Expressions"
%
% 
%\end{thebibliography}

\bibliography{paper}
\bibliographystyle{plain}


%----------------------------------------------------------------------------------------

\end{multicols}

\end{document}
